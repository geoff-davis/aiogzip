{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"aiogzip \u26a1\ufe0f","text":"<p>An asynchronous library for reading and writing gzip-compressed files.</p> <p> </p> <p><code>aiogzip</code> provides a fast, simple, and asyncio-native interface for handling <code>.gz</code> files, making it a useful complement to Python's built-in <code>gzip</code> module for asynchronous applications.</p> <p>It is designed for high-performance I/O operations, especially for text-based data pipelines, and integrates seamlessly with other <code>async</code> libraries like <code>aiocsv</code>.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Truly Asynchronous: Built with <code>asyncio</code> and <code>aiofiles</code> for non-blocking file I/O.</li> <li>High-Performance Text Processing: Significantly faster than the standard <code>gzip</code> library for text and JSONL file operations.</li> <li>Simple API: Mimics the interface of <code>gzip.open()</code>, making it easy to adopt.</li> <li>Separate Binary and Text Modes: <code>AsyncGzipBinaryFile</code> and <code>AsyncGzipTextFile</code> provide clear, type-safe handling of data.</li> <li>Excellent Compression Quality: Achieves compression ratios nearly identical to the standard <code>gzip</code> module.</li> <li><code>aiocsv</code> Integration: Read and write compressed CSV files effortlessly.</li> </ul>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li>Installation &amp; Usage</li> <li>Performance Benchmarks</li> <li>API Reference</li> <li>Contributing</li> </ul>"},{"location":"#quickstart","title":"Quickstart","text":"<p>Using <code>aiogzip</code> is as simple as using the standard <code>gzip</code> module, but with <code>async</code>/<code>await</code>.</p>"},{"location":"#writing-to-a-compressed-file","title":"Writing to a Compressed File","text":"<pre><code>import asyncio\nfrom aiogzip import AsyncGzipFile\n\nasync def main():\n    # Write binary data\n    async with AsyncGzipFile(\"file.gz\", \"wb\") as f:\n        await f.write(b\"Hello, async world!\")\n\n    # Write text data\n    async with AsyncGzipFile(\"file.txt.gz\", \"wt\") as f:\n        await f.write(\"This is a text file.\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"#reading-from-a-compressed-file","title":"Reading from a Compressed File","text":"<pre><code>import asyncio\nfrom aiogzip import AsyncGzipFile\n\nasync def main():\n    # Read the entire file\n    async with AsyncGzipFile(\"file.gz\", \"rb\") as f:\n        content = await f.read()\n        print(content)\n\n    # Iterate over lines in a text file\n    async with AsyncGzipFile(\"file.txt.gz\", \"rt\") as f:\n        async for line in f:\n            print(line.strip())\n\nasyncio.run(main())\n</code></pre>"},{"location":"#compatibility","title":"Compatibility","text":"<p><code>aiogzip</code> provides comprehensive compatibility with the standard <code>gzip</code> module's <code>GzipFile</code> API, including:</p> <ul> <li>\u2705 <code>seek()</code> and <code>tell()</code> methods for stream navigation (with the same performance characteristics as <code>gzip.GzipFile</code>)</li> <li>\u2705 <code>peek()</code> and <code>readinto()</code> for advanced reading patterns</li> <li>\u2705 Reading and writing gzip headers and metadata (e.g., <code>mtime</code>, <code>original_filename</code>)</li> <li>\u2705 Text and binary mode operations with proper encoding/decoding</li> <li>\u2705 Full compatibility with <code>tarfile</code> for reading <code>.tar.gz</code> archives</li> <li>\u2705 Seamless integration with <code>aiocsv</code> for CSV processing</li> </ul> <p>Note: <code>aiogzip</code> focuses on file-based operations and does not currently support in-memory compression/decompression (e.g., <code>gzip.compress</code>/<code>gzip.decompress</code>).</p>"},{"location":"api/","title":"API Reference","text":"<p><code>aiogzip</code> exposes its supported public API from the top-level package:</p> <ul> <li><code>AsyncGzipBinaryFile</code></li> <li><code>AsyncGzipTextFile</code></li> <li><code>AsyncGzipFile</code></li> </ul> <p>Implementation internals live in <code>aiogzip._common</code>, <code>aiogzip._binary</code>, and <code>aiogzip._text</code>. Treat those modules as private and unstable unless symbols are explicitly re-exported by <code>aiogzip</code>.</p>"},{"location":"api/#aiogzip","title":"aiogzip","text":"<p>Async gzip file reader/writer public API.</p>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile","title":"AsyncGzipBinaryFile","text":"<pre><code>AsyncGzipBinaryFile(filename: Union[str, bytes, Path, None], mode: str = 'rb', chunk_size: int = DEFAULT_CHUNK_SIZE, compresslevel: int = 6, mtime: Optional[Union[int, float]] = None, original_filename: Optional[Union[str, bytes]] = None, fileobj: Optional[WithAsyncReadWrite] = None, closefd: Optional[bool] = None)\n</code></pre> <p>An asynchronous gzip file reader/writer for binary data.</p> <p>This class provides async gzip compression/decompression for binary data, making it a drop-in replacement for gzip.open() in binary mode.</p> <p>Features: - Full compatibility with gzip.open() file format - Binary mode only (no text encoding/decoding) - Async context manager support - Configurable chunk size for performance tuning</p> Basic Usage <p>Interoperability with gzip.open():     # Files created by AsyncGzipBinaryFile can be read by gzip.open()     async with AsyncGzipBinaryFile(\"data.gz\", \"wb\") as f:         await f.write(b\"data\")</p> <pre><code>with gzip.open(\"data.gz\", \"rb\") as f:\n    data = f.read()  # Works perfectly!\n</code></pre> Source code in <code>src/aiogzip/_binary.py</code> <pre><code>def __init__(\n    self,\n    filename: Union[str, bytes, Path, None],\n    mode: str = \"rb\",\n    chunk_size: int = DEFAULT_CHUNK_SIZE,\n    compresslevel: int = 6,\n    mtime: Optional[Union[int, float]] = None,\n    original_filename: Optional[Union[str, bytes]] = None,\n    fileobj: Optional[WithAsyncReadWrite] = None,\n    closefd: Optional[bool] = None,\n) -&gt; None:\n    # Validate inputs using shared validation functions\n    _validate_filename(filename, fileobj)\n    _validate_chunk_size(chunk_size)\n\n    # Validate mode and derive file characteristics\n    mode_op, saw_b, saw_t, plus = _parse_mode_tokens(mode)\n    if saw_t:\n        raise ValueError(\"Binary mode cannot include text ('t')\")\n    if mode_op not in {\"r\", \"w\", \"a\", \"x\"}:\n        raise ValueError(f\"Invalid mode '{mode}'.\")\n\n    self._filename = filename\n    self._mode = mode\n    self._mode_op = mode_op\n    self._mode_plus = plus\n    self._writing_mode = mode_op in {\"w\", \"a\", \"x\"}\n    if self._writing_mode:\n        _validate_compresslevel(compresslevel)\n    self._chunk_size = chunk_size\n    self._compresslevel = compresslevel\n    self._header_mtime = _normalize_mtime(mtime)\n    self._header_filename_override = _validate_original_filename(original_filename)\n    self._external_file = fileobj\n    self._closefd = closefd if closefd is not None else fileobj is None\n\n    # Determine the underlying file mode based on gzip mode\n    file_mode_suffix = \"b\"\n    self._file_mode = f\"{mode_op}{file_mode_suffix}\"\n    if plus:\n        self._file_mode += \"+\"\n\n    self._file: Any = None\n    self._engine: ZlibEngine = None\n    self._buffer = bytearray()  # Use bytearray for efficient buffer growth\n    self._buffer_offset: int = 0  # Offset to the start of valid data in _buffer\n    self._is_closed: bool = False\n    self._eof: bool = False\n    self._owns_file: bool = False\n    self._crc: int = 0\n    self._input_size: int = 0\n    self._position: int = 0\n    self._mtime: Optional[int] = None\n    self._header_probe_buffer = bytearray()\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile--write-binary-data","title":"Write binary data","text":"<p>async with AsyncGzipBinaryFile(\"data.gz\", \"wb\") as f:     await f.write(b\"Hello, World!\")</p>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile--read-binary-data","title":"Read binary data","text":"<p>async with AsyncGzipBinaryFile(\"data.gz\", \"rb\") as f:     data = await f.read()  # Returns bytes</p>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.closed","title":"closed  <code>property</code>","text":"<pre><code>closed: bool\n</code></pre> <p>Return True when this file has been closed.</p>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.mtime","title":"mtime  <code>property</code>","text":"<pre><code>mtime: Optional[int]\n</code></pre> <p>Return the gzip member mtime after the header has been read.</p>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.name","title":"name  <code>property</code>","text":"<pre><code>name: Union[str, bytes, Path, None]\n</code></pre> <p>Return the name of the file.</p> <p>This property provides compatibility with the standard file API. Returns the filename passed to the constructor, or None if the file was opened with a file object instead of a filename.</p> <p>Returns:</p> Type Description <code>Union[str, bytes, Path, None]</code> <p>The filename as str, bytes, or Path, or None if opened via fileobj.</p>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.__aenter__","title":"__aenter__  <code>async</code>","text":"<pre><code>__aenter__() -&gt; AsyncGzipBinaryFile\n</code></pre> <p>Enter the async context manager and initialize resources.</p> Source code in <code>src/aiogzip/_binary.py</code> <pre><code>async def __aenter__(self) -&gt; \"AsyncGzipBinaryFile\":\n    \"\"\"Enter the async context manager and initialize resources.\"\"\"\n    if self._external_file is not None:\n        self._file = self._external_file\n        self._owns_file = False\n    else:\n        if self._filename is None:\n            raise ValueError(\"Filename must be provided when fileobj is not given\")\n        self._file = await aiofiles.open(  # type: ignore\n            self._filename, self._file_mode\n        )\n        self._owns_file = True\n\n    # Initialize compression/decompression engine based on mode\n    if self._writing_mode:\n        self._engine = zlib.compressobj(\n            level=self._compresslevel, wbits=-zlib.MAX_WBITS\n        )\n        header = _build_gzip_header(\n            _derive_header_filename(self._header_filename_override, self._filename),\n            self._header_mtime,\n            self._compresslevel,\n        )\n        await self._file.write(header)\n        self._crc = 0\n        self._input_size = 0\n    else:  # read mode\n        self._engine = zlib.decompressobj(wbits=GZIP_WBITS)\n        self._position = 0\n        self._mtime = None\n        self._header_probe_buffer.clear()\n\n    return self\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.__aexit__","title":"__aexit__  <code>async</code>","text":"<pre><code>__aexit__(exc_type: Optional[type], exc_val: Optional[BaseException], exc_tb: Optional[Any]) -&gt; None\n</code></pre> <p>Exit the context manager, flushing and closing the file.</p> Source code in <code>src/aiogzip/_binary.py</code> <pre><code>async def __aexit__(\n    self,\n    exc_type: Optional[type],\n    exc_val: Optional[BaseException],\n    exc_tb: Optional[Any],\n) -&gt; None:\n    \"\"\"Exit the context manager, flushing and closing the file.\"\"\"\n    await self.close()\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.__aiter__","title":"__aiter__","text":"<pre><code>__aiter__() -&gt; AsyncGzipBinaryFile\n</code></pre> <p>Make AsyncGzipBinaryFile iterable over newline-delimited chunks.</p> Source code in <code>src/aiogzip/_binary.py</code> <pre><code>def __aiter__(self) -&gt; \"AsyncGzipBinaryFile\":\n    \"\"\"Make AsyncGzipBinaryFile iterable over newline-delimited chunks.\"\"\"\n    return self\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.__anext__","title":"__anext__  <code>async</code>","text":"<pre><code>__anext__() -&gt; bytes\n</code></pre> <p>Return the next line from the binary stream.</p> Source code in <code>src/aiogzip/_binary.py</code> <pre><code>async def __anext__(self) -&gt; bytes:\n    \"\"\"Return the next line from the binary stream.\"\"\"\n    if self._is_closed:\n        raise StopAsyncIteration\n    line = await self.readline()\n    if line == b\"\":\n        raise StopAsyncIteration\n    return line\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.close","title":"close  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Flushes any remaining compressed data and closes the file.</p> Source code in <code>src/aiogzip/_binary.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"Flushes any remaining compressed data and closes the file.\"\"\"\n    if self._is_closed:\n        return\n\n    # Mark as closed immediately to prevent concurrent close attempts\n    self._is_closed = True\n\n    try:\n        if self._writing_mode and self._file is not None:\n            # Flush the compressor to write the gzip trailer\n            remaining_data = self._engine.flush()\n            if remaining_data:\n                await self._file.write(remaining_data)\n            trailer = _build_gzip_trailer(self._crc, self._input_size)\n            await self._file.write(trailer)\n\n        if self._file is not None and (self._owns_file or self._closefd):\n            # Close only if we own it or closefd=True\n            close_method = getattr(self._file, \"close\", None)\n            if callable(close_method):\n                result = close_method()\n                if hasattr(result, \"__await__\"):\n                    await result\n    except Exception:\n        # If an error occurs during close, we're still closed\n        # but we need to propagate the exception\n        raise\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.detach","title":"detach","text":"<pre><code>detach() -&gt; Any\n</code></pre> <p>Detach is unsupported to mirror gzip.GzipFile behavior.</p> Source code in <code>src/aiogzip/_binary.py</code> <pre><code>def detach(self) -&gt; Any:\n    \"\"\"Detach is unsupported to mirror gzip.GzipFile behavior.\"\"\"\n    raise io.UnsupportedOperation(\"detach\")\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.fileno","title":"fileno","text":"<pre><code>fileno() -&gt; int\n</code></pre> <p>Return the underlying file descriptor number.</p> Source code in <code>src/aiogzip/_binary.py</code> <pre><code>def fileno(self) -&gt; int:\n    \"\"\"Return the underlying file descriptor number.\"\"\"\n    if self._file is None:\n        raise ValueError(\"File not opened. Use async context manager.\")\n    fileno_method = getattr(self._file, \"fileno\", None)\n    if fileno_method is None:\n        raise io.UnsupportedOperation(\"fileno() not supported by underlying file\")\n    result = fileno_method()\n    if hasattr(result, \"__await__\"):\n        raise io.UnsupportedOperation(\n            \"fileno() is not awaitable in underlying file\"\n        )\n    return int(result)\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.flush","title":"flush  <code>async</code>","text":"<pre><code>flush() -&gt; None\n</code></pre> <p>Flush any buffered compressed data to the file.</p> <p>In write/append mode, this forces any buffered compressed data to be written to the underlying file. Note that this does NOT write the gzip trailer - use close() for that.</p> <p>In read mode, this is a no-op for compatibility with the file API.</p> <p>Examples:</p> <p>async with AsyncGzipBinaryFile(\"file.gz\", \"wb\") as f:     await f.write(b\"Hello\")     await f.flush()  # Ensure data is written     await f.write(b\" World\")</p> Source code in <code>src/aiogzip/_binary.py</code> <pre><code>async def flush(self) -&gt; None:\n    \"\"\"\n    Flush any buffered compressed data to the file.\n\n    In write/append mode, this forces any buffered compressed data to be\n    written to the underlying file. Note that this does NOT write the gzip\n    trailer - use close() for that.\n\n    In read mode, this is a no-op for compatibility with the file API.\n\n    Examples:\n        async with AsyncGzipBinaryFile(\"file.gz\", \"wb\") as f:\n            await f.write(b\"Hello\")\n            await f.flush()  # Ensure data is written\n            await f.write(b\" World\")\n    \"\"\"\n    if self._is_closed:\n        raise ValueError(\"I/O operation on closed file.\")\n\n    if self._writing_mode and self._file is not None:\n        # Flush any buffered compressed data (but not the final trailer)\n        # Using Z_SYNC_FLUSH allows us to flush without ending the stream\n        try:\n            flushed_data = self._engine.flush(zlib.Z_SYNC_FLUSH)\n            if flushed_data:\n                await self._file.write(flushed_data)\n\n            # Also flush the underlying file if it has a flush method\n            flush_method = getattr(self._file, \"flush\", None)\n            if callable(flush_method):\n                result = flush_method()\n                if hasattr(result, \"__await__\"):\n                    await result\n        except zlib.error as e:\n            raise OSError(f\"Error flushing compressed data: {e}\") from e\n        except OSError:\n            raise\n        except Exception as e:\n            raise OSError(f\"Unexpected error during flush: {e}\") from e\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.isatty","title":"isatty","text":"<pre><code>isatty() -&gt; bool\n</code></pre> <p>Return True if the underlying stream is interactive.</p> Source code in <code>src/aiogzip/_binary.py</code> <pre><code>def isatty(self) -&gt; bool:\n    \"\"\"Return True if the underlying stream is interactive.\"\"\"\n    if self._file is None:\n        return False\n    isatty_method = getattr(self._file, \"isatty\", None)\n    if not callable(isatty_method):\n        return False\n    result = isatty_method()\n    if hasattr(result, \"__await__\"):\n        close_method = getattr(result, \"close\", None)\n        if callable(close_method):\n            close_method()\n        return False\n    return bool(result)\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.peek","title":"peek  <code>async</code>","text":"<pre><code>peek(size: int = -1) -&gt; bytes\n</code></pre> <p>Return up to size bytes without advancing the read position.</p> Source code in <code>src/aiogzip/_binary.py</code> <pre><code>async def peek(self, size: int = -1) -&gt; bytes:\n    \"\"\"Return up to size bytes without advancing the read position.\"\"\"\n    if self._mode_op != \"r\":\n        raise OSError(\"File not open for reading\")\n    if self._file is None:\n        raise ValueError(\"File not opened. Use async context manager.\")\n    available = len(self._buffer) - self._buffer_offset\n    target = size\n    if target is None or target &lt;= 0:\n        target = available if available &gt; 0 else 1\n    while available &lt; target and not self._eof:\n        await self._fill_buffer()\n        available = len(self._buffer) - self._buffer_offset\n        if available == 0 and self._eof:\n            break\n    end = self._buffer_offset + min(target, available)\n    return bytes(self._buffer[self._buffer_offset : end])\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.raw","title":"raw","text":"<pre><code>raw() -&gt; Any\n</code></pre> <p>Expose the underlying file object for advanced integrations.</p> Source code in <code>src/aiogzip/_binary.py</code> <pre><code>def raw(self) -&gt; Any:\n    \"\"\"Expose the underlying file object for advanced integrations.\"\"\"\n    return self._file\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.read","title":"read  <code>async</code>","text":"<pre><code>read(size: int = -1) -&gt; bytes\n</code></pre> <p>Reads and decompresses binary data from the file.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>Number of bytes to read (-1 for all remaining data)</p> <code>-1</code> <p>Returns:</p> Type Description <code>bytes</code> <p>bytes</p> <p>Examples:</p> <p>async with AsyncGzipBinaryFile(\"file.gz\", \"rb\") as f:     data = await f.read()  # Returns bytes     partial = await f.read(100)  # Returns first 100 bytes</p> Source code in <code>src/aiogzip/_binary.py</code> <pre><code>async def read(self, size: int = -1) -&gt; bytes:\n    \"\"\"\n    Reads and decompresses binary data from the file.\n\n    Args:\n        size: Number of bytes to read (-1 for all remaining data)\n\n    Returns:\n        bytes\n\n    Examples:\n        async with AsyncGzipBinaryFile(\"file.gz\", \"rb\") as f:\n            data = await f.read()  # Returns bytes\n            partial = await f.read(100)  # Returns first 100 bytes\n    \"\"\"\n    if self._mode_op != \"r\":\n        raise OSError(\"File not open for reading\")\n    if self._is_closed:\n        raise ValueError(\"I/O operation on closed file.\")\n    if self._file is None:\n        raise ValueError(\"File not opened. Use async context manager.\")\n\n    if size is None:\n        size = -1\n    if size &lt; 0:\n        size = -1\n\n    # If size is -1, read all data in chunks to avoid memory issues\n    if size == -1:\n        # Return buffered data + read remaining (no recursion)\n        chunks = []\n        total_read = 0\n        if self._buffer_offset &lt; len(self._buffer):\n            chunk = bytes(self._buffer[self._buffer_offset :])\n            chunks.append(chunk)\n            total_read += len(chunk)\n\n        del self._buffer[:]  # Clear while retaining capacity\n        self._buffer_offset = 0\n\n        while not self._eof:\n            await self._fill_buffer()\n            if self._buffer:\n                chunk = bytes(self._buffer)\n                chunks.append(chunk)\n                total_read += len(chunk)\n                del self._buffer[:]  # Clear while retaining capacity\n\n        data = b\"\".join(chunks)\n        self._position += total_read\n        return data\n    else:\n        # Otherwise, read until the buffer has enough data to satisfy the request.\n        while (len(self._buffer) - self._buffer_offset) &lt; size and not self._eof:\n            # If buffer has too much garbage at the front, compact it\n            if self._buffer_offset &gt; self.BUFFER_COMPACTION_THRESHOLD:\n                del self._buffer[: self._buffer_offset]\n                self._buffer_offset = 0\n\n            await self._fill_buffer()\n\n        # Determine how much we can actually read\n        available = len(self._buffer) - self._buffer_offset\n        actual_read_size = min(size, available)\n\n        data_to_return = bytes(\n            self._buffer[\n                self._buffer_offset : self._buffer_offset + actual_read_size\n            ]\n        )\n        self._buffer_offset += actual_read_size\n        self._position += actual_read_size\n\n        # If we consumed everything, reset to keep buffer clean\n        if self._buffer_offset &gt;= len(self._buffer):\n            del self._buffer[:]\n            self._buffer_offset = 0\n\n        return data_to_return\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.read1","title":"read1  <code>async</code>","text":"<pre><code>read1(size: int = -1) -&gt; bytes\n</code></pre> <p>Read up to size bytes from the buffer without looping.</p> Source code in <code>src/aiogzip/_binary.py</code> <pre><code>async def read1(self, size: int = -1) -&gt; bytes:\n    \"\"\"Read up to size bytes from the buffer without looping.\"\"\"\n    return await self.read(size)\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.readinto","title":"readinto  <code>async</code>","text":"<pre><code>readinto(b: Union[bytearray, memoryview]) -&gt; int\n</code></pre> <p>Read bytes directly into a pre-allocated, writable buffer.</p> Source code in <code>src/aiogzip/_binary.py</code> <pre><code>async def readinto(self, b: Union[bytearray, memoryview]) -&gt; int:\n    \"\"\"Read bytes directly into a pre-allocated, writable buffer.\"\"\"\n    if self._mode_op != \"r\":\n        raise OSError(\"File not open for reading\")\n    if self._file is None:\n        raise ValueError(\"File not opened. Use async context manager.\")\n    view = memoryview(b)\n    if view.readonly:\n        raise TypeError(\"readinto() argument must be writable\")\n    data = await self.read(len(view))\n    view[: len(data)] = data\n    return len(data)\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.readinto1","title":"readinto1  <code>async</code>","text":"<pre><code>readinto1(b: Union[bytearray, memoryview]) -&gt; int\n</code></pre> <p>Read directly into the buffer without looping.</p> Source code in <code>src/aiogzip/_binary.py</code> <pre><code>async def readinto1(self, b: Union[bytearray, memoryview]) -&gt; int:\n    \"\"\"Read directly into the buffer without looping.\"\"\"\n    return await self.readinto(b)\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.readline","title":"readline  <code>async</code>","text":"<pre><code>readline(limit: int = -1) -&gt; bytes\n</code></pre> <p>Read and return one line from the binary stream.</p> Source code in <code>src/aiogzip/_binary.py</code> <pre><code>async def readline(self, limit: int = -1) -&gt; bytes:\n    \"\"\"Read and return one line from the binary stream.\"\"\"\n    if self._mode_op != \"r\":\n        raise OSError(\"File not open for reading\")\n    if self._is_closed:\n        raise ValueError(\"I/O operation on closed file.\")\n    if self._file is None:\n        raise ValueError(\"File not opened. Use async context manager.\")\n    if limit is None:\n        limit = -1\n    if limit == 0:\n        return b\"\"\n\n    chunks: List[bytes] = []\n    total = 0\n    while True:\n        if self._buffer_offset &gt;= len(self._buffer):\n            if self._eof:\n                break\n            await self._fill_buffer()\n            if self._buffer_offset &gt;= len(self._buffer) and self._eof:\n                break\n            if self._buffer_offset &gt;= len(self._buffer):\n                continue\n\n        start = self._buffer_offset\n        end = len(self._buffer)\n        newline_index = self._buffer.find(b\"\\n\", start)\n        if newline_index != -1:\n            end = newline_index + 1\n        if limit != -1:\n            remaining = limit - total\n            if remaining &lt;= 0:\n                break\n            end = min(end, start + remaining)\n\n        if end &lt;= start:\n            break\n\n        chunk = bytes(self._buffer[start:end])\n        chunks.append(chunk)\n        consumed = end - start\n        self._buffer_offset = end\n        self._position += consumed\n        total += consumed\n\n        if self._buffer_offset &gt;= len(self._buffer):\n            del self._buffer[:]\n            self._buffer_offset = 0\n\n        if (newline_index != -1 and end == newline_index + 1) or (\n            limit != -1 and total &gt;= limit\n        ):\n            break\n\n    return b\"\".join(chunks)\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.readlines","title":"readlines  <code>async</code>","text":"<pre><code>readlines(hint: int = -1) -&gt; List[bytes]\n</code></pre> <p>Read and return a list of lines from the binary stream.</p> Source code in <code>src/aiogzip/_binary.py</code> <pre><code>async def readlines(self, hint: int = -1) -&gt; List[bytes]:\n    \"\"\"Read and return a list of lines from the binary stream.\"\"\"\n    if self._mode_op != \"r\":\n        raise OSError(\"File not open for reading\")\n    if self._is_closed:\n        raise ValueError(\"I/O operation on closed file.\")\n\n    lines: List[bytes] = []\n    total = 0\n    while True:\n        line = await self.readline()\n        if not line:\n            break\n        lines.append(line)\n        total += len(line)\n        if hint &gt; 0 and total &gt;= hint:\n            break\n    return lines\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.seek","title":"seek  <code>async</code>","text":"<pre><code>seek(offset: int, whence: int = os.SEEK_SET) -&gt; int\n</code></pre> <p>Move to a new file position, mirroring gzip.GzipFile semantics.</p> Source code in <code>src/aiogzip/_binary.py</code> <pre><code>async def seek(self, offset: int, whence: int = os.SEEK_SET) -&gt; int:\n    \"\"\"Move to a new file position, mirroring gzip.GzipFile semantics.\"\"\"\n    if self._file is None:\n        raise ValueError(\"File not opened. Use async context manager.\")\n    if self._writing_mode:\n        if whence == os.SEEK_CUR:\n            target = self._position + offset\n        elif whence == os.SEEK_SET:\n            target = offset\n        else:\n            raise ValueError(\"Seek from end not supported in write mode\")\n        if target &lt; self._position:\n            raise OSError(\"Negative seek in write mode\")\n        count = target - self._position\n        if count &gt; 0:\n            zero_chunk = b\"\\x00\" * min(1024, count)\n            remaining = count\n            while remaining &gt; 0:\n                chunk = (\n                    zero_chunk\n                    if remaining &gt;= len(zero_chunk)\n                    else zero_chunk[:remaining]\n                )\n                await self.write(chunk)\n                remaining -= len(chunk)\n        return self._position\n\n    if whence == os.SEEK_SET:\n        target = offset\n    elif whence == os.SEEK_CUR:\n        target = self._position + offset\n    elif whence == os.SEEK_END:\n        raise ValueError(\"Seek from end not supported in read mode\")\n    else:\n        raise ValueError(\"Invalid whence value\")\n\n    if target &lt; 0:\n        raise OSError(\"Negative seek in read mode\")\n\n    if target &lt; self._position:\n        await self._rewind_reader()\n\n    await self._consume_bytes(target - self._position)\n    return self._position\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.tell","title":"tell  <code>async</code>","text":"<pre><code>tell() -&gt; int\n</code></pre> <p>Return the current uncompressed file position.</p> Source code in <code>src/aiogzip/_binary.py</code> <pre><code>async def tell(self) -&gt; int:\n    \"\"\"Return the current uncompressed file position.\"\"\"\n    return self._position\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.truncate","title":"truncate","text":"<pre><code>truncate(size: Optional[int] = None) -&gt; int\n</code></pre> <p>Truncation is unsupported for gzip-compressed streams.</p> Source code in <code>src/aiogzip/_binary.py</code> <pre><code>def truncate(self, size: Optional[int] = None) -&gt; int:\n    \"\"\"Truncation is unsupported for gzip-compressed streams.\"\"\"\n    raise io.UnsupportedOperation(\"truncate\")\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.write","title":"write  <code>async</code>","text":"<pre><code>write(data: Union[bytes, bytearray, memoryview]) -&gt; int\n</code></pre> <p>Compresses and writes binary data to the file.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[bytes, bytearray, memoryview]</code> <p>Bytes to write</p> required <p>Examples:</p> <p>async with AsyncGzipBinaryFile(\"file.gz\", \"wb\") as f:     await f.write(b\"Hello, World!\")  # Bytes input</p> Source code in <code>src/aiogzip/_binary.py</code> <pre><code>async def write(self, data: Union[bytes, bytearray, memoryview]) -&gt; int:\n    \"\"\"\n    Compresses and writes binary data to the file.\n\n    Args:\n        data: Bytes to write\n\n    Examples:\n        async with AsyncGzipBinaryFile(\"file.gz\", \"wb\") as f:\n            await f.write(b\"Hello, World!\")  # Bytes input\n    \"\"\"\n    if not self._writing_mode:\n        raise OSError(\"File not open for writing\")\n    if self._is_closed:\n        raise ValueError(\"I/O operation on closed file.\")\n    if self._file is None:\n        raise ValueError(\"File not opened. Use async context manager.\")\n\n    buffer = self._coerce_byteslike(data)\n    self._crc = zlib.crc32(buffer, self._crc)\n    self._input_size += len(buffer)\n    self._position = self._input_size\n\n    try:\n        compressed = self._engine.compress(buffer)\n        if compressed:\n            await self._file.write(compressed)\n    except zlib.error as e:\n        raise OSError(f\"Error compressing data: {e}\") from e\n    except OSError:\n        # Re-raise I/O errors as-is\n        raise\n    except Exception as e:\n        raise OSError(f\"Unexpected error during compression: {e}\") from e\n\n    return len(buffer)\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipBinaryFile.writelines","title":"writelines  <code>async</code>","text":"<pre><code>writelines(lines: Iterable[bytes]) -&gt; None\n</code></pre> <p>Write a sequence of bytes-like lines to the binary stream.</p> Source code in <code>src/aiogzip/_binary.py</code> <pre><code>async def writelines(self, lines: Iterable[bytes]) -&gt; None:\n    \"\"\"Write a sequence of bytes-like lines to the binary stream.\"\"\"\n    if not self._writing_mode:\n        raise OSError(\"File not open for writing\")\n    if self._is_closed:\n        raise ValueError(\"I/O operation on closed file.\")\n\n    for line in lines:\n        await self.write(line)\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipTextFile","title":"AsyncGzipTextFile","text":"<pre><code>AsyncGzipTextFile(filename: Union[str, bytes, Path, None], mode: str = 'rt', chunk_size: int = AsyncGzipBinaryFile.DEFAULT_CHUNK_SIZE, encoding: Optional[str] = 'utf-8', errors: Optional[str] = 'strict', newline: Union[str, None] = None, compresslevel: int = 6, mtime: Optional[Union[int, float]] = None, original_filename: Optional[Union[str, bytes]] = None, fileobj: Optional[WithAsyncReadWrite] = None, closefd: Optional[bool] = None)\n</code></pre> <p>An asynchronous gzip file reader/writer for text data.</p> <p>This class wraps AsyncGzipBinaryFile and provides text mode operations with proper UTF-8 handling for multi-byte characters.</p> <p>Features: - Full compatibility with gzip.open() file format - Text mode with automatic encoding/decoding - Proper handling of multi-byte UTF-8 characters - Line-by-line iteration support - Async context manager support</p> Basic Usage Source code in <code>src/aiogzip/_text.py</code> <pre><code>def __init__(\n    self,\n    filename: Union[str, bytes, Path, None],\n    mode: str = \"rt\",\n    chunk_size: int = AsyncGzipBinaryFile.DEFAULT_CHUNK_SIZE,\n    encoding: Optional[str] = \"utf-8\",\n    errors: Optional[str] = \"strict\",\n    newline: Union[str, None] = None,\n    compresslevel: int = 6,\n    mtime: Optional[Union[int, float]] = None,\n    original_filename: Optional[Union[str, bytes]] = None,\n    fileobj: Optional[WithAsyncReadWrite] = None,\n    closefd: Optional[bool] = None,\n) -&gt; None:\n    # Validate inputs using shared validation functions\n    _validate_filename(filename, fileobj)\n    _validate_chunk_size(chunk_size)\n\n    # Validate text-specific parameters\n    if encoding is None:\n        encoding = \"utf-8\"\n    if not encoding:\n        raise ValueError(\"Encoding cannot be empty\")\n    if errors is None:\n        errors = \"strict\"\n    if newline not in {None, \"\", \"\\n\", \"\\r\", \"\\r\\n\"}:\n        raise ValueError(f\"illegal newline value: {newline}\")\n\n    mode_op, saw_b, saw_t, plus = _parse_mode_tokens(mode)\n    if saw_b:\n        raise ValueError(\"Text mode cannot include binary ('b')\")\n    if mode_op not in {\"r\", \"w\", \"a\", \"x\"}:\n        raise ValueError(f\"Invalid mode '{mode}'.\")\n\n    self._filename = filename\n    self._mode = mode\n    self._mode_op = mode_op\n    self._mode_plus = plus\n    self._writing_mode = mode_op in {\"w\", \"a\", \"x\"}\n    if self._writing_mode:\n        _validate_compresslevel(compresslevel)\n    self._chunk_size = chunk_size\n    self._encoding = encoding\n    self._errors = errors\n    self._newline = newline\n    self._compresslevel = compresslevel\n    self._header_mtime = _normalize_mtime(mtime)\n    self._header_filename_override = _validate_original_filename(original_filename)\n    self._external_file = fileobj\n    self._closefd = closefd if closefd is not None else fileobj is None\n\n    # Determine the underlying binary file mode\n    self._binary_mode = f\"{mode_op}b\"\n    if plus:\n        self._binary_mode += \"+\"\n\n    self._binary_file: Optional[AsyncGzipBinaryFile] = None\n    self._is_closed: bool = False\n\n    # Decoder and buffer state\n    self._decoder = codecs.getincrementaldecoder(self._encoding)(\n        errors=self._errors\n    )\n    self._text_buffer: str = \"\"  # Central buffer for decoded text\n    self._trailing_cr: bool = False  # Track if last decoded chunk ended with \\r\n    self._cookie_cache: Dict[int, _TextCookieState] = {}\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipTextFile--write-text-data","title":"Write text data","text":"<p>async with AsyncGzipTextFile(\"data.gz\", \"wt\") as f:     await f.write(\"Hello, World!\")  # String input</p>"},{"location":"api/#aiogzip.AsyncGzipTextFile--read-text-data","title":"Read text data","text":"<p>async with AsyncGzipTextFile(\"data.gz\", \"rt\") as f:     text = await f.read()  # Returns string</p>"},{"location":"api/#aiogzip.AsyncGzipTextFile--line-by-line-iteration","title":"Line-by-line iteration","text":"<p>async with AsyncGzipTextFile(\"data.gz\", \"rt\") as f:     async for line in f:         print(line.strip())</p>"},{"location":"api/#aiogzip.AsyncGzipTextFile.buffer","title":"buffer  <code>property</code>","text":"<pre><code>buffer: AsyncGzipBinaryFile\n</code></pre> <p>Expose the underlying binary gzip stream.</p>"},{"location":"api/#aiogzip.AsyncGzipTextFile.closed","title":"closed  <code>property</code>","text":"<pre><code>closed: bool\n</code></pre> <p>Return True when this file has been closed.</p>"},{"location":"api/#aiogzip.AsyncGzipTextFile.encoding","title":"encoding  <code>property</code>","text":"<pre><code>encoding: str\n</code></pre> <p>Return the configured text encoding.</p>"},{"location":"api/#aiogzip.AsyncGzipTextFile.errors","title":"errors  <code>property</code>","text":"<pre><code>errors: str\n</code></pre> <p>Return the configured text error handler.</p>"},{"location":"api/#aiogzip.AsyncGzipTextFile.name","title":"name  <code>property</code>","text":"<pre><code>name: Union[str, bytes, Path, None]\n</code></pre> <p>Return the name of the file.</p> <p>This property provides compatibility with the standard file API. Returns the filename passed to the constructor, or None if the file was opened with a file object instead of a filename.</p> <p>Returns:</p> Type Description <code>Union[str, bytes, Path, None]</code> <p>The filename as str, bytes, or Path, or None if opened via fileobj.</p>"},{"location":"api/#aiogzip.AsyncGzipTextFile.newlines","title":"newlines  <code>property</code>","text":"<pre><code>newlines: Optional[str]\n</code></pre> <p>Return newline handling configuration.</p>"},{"location":"api/#aiogzip.AsyncGzipTextFile.__aenter__","title":"__aenter__  <code>async</code>","text":"<pre><code>__aenter__() -&gt; AsyncGzipTextFile\n</code></pre> <p>Enter the async context manager and initialize resources.</p> Source code in <code>src/aiogzip/_text.py</code> <pre><code>async def __aenter__(self) -&gt; \"AsyncGzipTextFile\":\n    \"\"\"Enter the async context manager and initialize resources.\"\"\"\n    filename = os.fspath(self._filename) if self._filename is not None else None\n    self._binary_file = AsyncGzipBinaryFile(\n        filename=filename,\n        mode=self._binary_mode,\n        chunk_size=self._chunk_size,\n        compresslevel=self._compresslevel,\n        mtime=self._header_mtime,\n        original_filename=self._header_filename_override,\n        fileobj=self._external_file,\n        closefd=self._closefd,\n    )\n    await self._binary_file.__aenter__()\n    return self\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipTextFile.__aexit__","title":"__aexit__  <code>async</code>","text":"<pre><code>__aexit__(exc_type: Optional[type], exc_val: Optional[BaseException], exc_tb: Optional[Any]) -&gt; None\n</code></pre> <p>Exit the context manager, flushing and closing the file.</p> Source code in <code>src/aiogzip/_text.py</code> <pre><code>async def __aexit__(\n    self,\n    exc_type: Optional[type],\n    exc_val: Optional[BaseException],\n    exc_tb: Optional[Any],\n) -&gt; None:\n    \"\"\"Exit the context manager, flushing and closing the file.\"\"\"\n    await self.close()\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipTextFile.__aiter__","title":"__aiter__","text":"<pre><code>__aiter__() -&gt; AsyncGzipTextFile\n</code></pre> <p>Make AsyncGzipTextFile iterable for line-by-line reading.</p> Source code in <code>src/aiogzip/_text.py</code> <pre><code>def __aiter__(self) -&gt; \"AsyncGzipTextFile\":\n    \"\"\"Make AsyncGzipTextFile iterable for line-by-line reading.\"\"\"\n    return self\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipTextFile.__anext__","title":"__anext__  <code>async</code>","text":"<pre><code>__anext__() -&gt; str\n</code></pre> <p>Return the next line from the file.</p> Source code in <code>src/aiogzip/_text.py</code> <pre><code>async def __anext__(self) -&gt; str:\n    \"\"\"Return the next line from the file.\"\"\"\n    if self._is_closed:\n        raise StopAsyncIteration\n\n    # Read until we get a complete line\n    while True:\n        # Try to get a line from our buffer using newline-aware search\n        pos, length = self._get_line_terminator_pos(self._text_buffer)\n        if pos != -1:\n            # Found a line terminator\n            line = self._text_buffer[: pos + length]\n            self._text_buffer = self._text_buffer[pos + length :]\n            return line\n\n        # Read more data\n        has_more = await self._read_chunk_and_decode()\n        if not has_more:\n            # EOF\n            if self._text_buffer:\n                result = self._text_buffer\n                self._text_buffer = \"\"  # Clear buffer\n                return result  # Last line without newline\n            else:\n                raise StopAsyncIteration\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipTextFile.close","title":"close  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Closes the file.</p> Source code in <code>src/aiogzip/_text.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"Closes the file.\"\"\"\n    if self._is_closed:\n        return\n\n    # Mark as closed immediately to prevent concurrent close attempts\n    self._is_closed = True\n    self._cookie_cache.clear()\n\n    try:\n        if not self._writing_mode:\n            # Flush the decoder to ensure all buffered bytes are processed\n            # This is important for handling incomplete multi-byte characters at EOF\n            self._decoder.decode(b\"\", final=True)\n\n        if self._binary_file is not None:\n            await self._binary_file.close()\n    except Exception:\n        # If an error occurs during close, we're still closed\n        # but we need to propagate the exception\n        raise\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipTextFile.flush","title":"flush  <code>async</code>","text":"<pre><code>flush() -&gt; None\n</code></pre> <p>Flush any buffered data to the file.</p> <p>In write/append mode, this forces any buffered text to be encoded and written to the underlying binary file.</p> <p>In read mode, this is a no-op for compatibility with the file API.</p> <p>Examples:</p> <p>async with AsyncGzipTextFile(\"file.gz\", \"wt\") as f:     await f.write(\"Hello\")     await f.flush()  # Ensure data is written     await f.write(\" World\")</p> Source code in <code>src/aiogzip/_text.py</code> <pre><code>async def flush(self) -&gt; None:\n    \"\"\"\n    Flush any buffered data to the file.\n\n    In write/append mode, this forces any buffered text to be encoded\n    and written to the underlying binary file.\n\n    In read mode, this is a no-op for compatibility with the file API.\n\n    Examples:\n        async with AsyncGzipTextFile(\"file.gz\", \"wt\") as f:\n            await f.write(\"Hello\")\n            await f.flush()  # Ensure data is written\n            await f.write(\" World\")\n    \"\"\"\n    if self._is_closed:\n        raise ValueError(\"I/O operation on closed file.\")\n\n    if self._binary_file is not None:\n        await self._binary_file.flush()\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipTextFile.read","title":"read  <code>async</code>","text":"<pre><code>read(size: int = -1) -&gt; str\n</code></pre> <p>Reads and decodes text data from the file.</p> <p>Parameters:</p> Name Type Description Default <code>size</code> <code>int</code> <p>Number of characters to read (-1 for all remaining data)</p> <code>-1</code> <p>Returns:</p> Type Description <code>str</code> <p>str</p> <p>Examples:</p> <p>async with AsyncGzipTextFile(\"file.gz\", \"rt\") as f:     text = await f.read()  # Returns string     partial = await f.read(100)  # Returns first 100 chars as string</p> Source code in <code>src/aiogzip/_text.py</code> <pre><code>async def read(self, size: int = -1) -&gt; str:\n    \"\"\"\n    Reads and decodes text data from the file.\n\n    Args:\n        size: Number of characters to read (-1 for all remaining data)\n\n    Returns:\n        str\n\n    Examples:\n        async with AsyncGzipTextFile(\"file.gz\", \"rt\") as f:\n            text = await f.read()  # Returns string\n            partial = await f.read(100)  # Returns first 100 chars as string\n    \"\"\"\n    if self._mode_op != \"r\":\n        raise OSError(\"File not open for reading\")\n    if self._is_closed:\n        raise ValueError(\"I/O operation on closed file.\")\n    if self._binary_file is None:\n        raise ValueError(\"File not opened. Use async context manager.\")\n\n    if size is None:\n        size = -1\n    if size &lt; 0:\n        size = -1\n\n    # Handle read(0) - should return empty string without draining buffer\n    if size == 0:\n        return \"\"\n\n    if size == -1:\n        # Read all remaining data\n        # We use a list to accumulate chunks for performance\n        chunks = [self._text_buffer]\n        self._text_buffer = \"\"\n\n        while True:\n            has_more = await self._read_chunk_and_decode()\n            if not has_more:\n                break\n            if self._text_buffer:\n                chunks.append(self._text_buffer)\n                self._text_buffer = \"\"\n\n        return \"\".join(chunks)\n    else:\n        # Check if we have enough data in our text buffer\n        while len(self._text_buffer) &lt; size:\n            has_more = await self._read_chunk_and_decode()\n            if not has_more:\n                break\n\n        # Return the requested number of characters\n        result = self._text_buffer[:size]\n        self._text_buffer = self._text_buffer[size:]\n        return result\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipTextFile.readline","title":"readline  <code>async</code>","text":"<pre><code>readline(limit: int = -1) -&gt; str\n</code></pre> <p>Read and return one line from the file.</p> <p>A line is defined as text ending with a newline character ('\\n'). If the file ends without a newline, the last line is returned without one.</p> <p>Parameters:</p> Name Type Description Default <code>limit</code> <code>int</code> <p>Maximum number of characters to return. Stops at newline, EOF, or once the limit is reached (matching TextIOBase semantics).</p> <code>-1</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The next line from the file, including the newline if present.  Returns empty string at EOF.</p> <p>Examples:</p> <p>async with AsyncGzipTextFile(\"file.gz\", \"rt\") as f:     line = await f.readline()  # Read one line     while line:         print(line.rstrip())         line = await f.readline()</p> Source code in <code>src/aiogzip/_text.py</code> <pre><code>async def readline(self, limit: int = -1) -&gt; str:\n    \"\"\"\n    Read and return one line from the file.\n\n    A line is defined as text ending with a newline character ('\\\\n').\n    If the file ends without a newline, the last line is returned without one.\n\n    Args:\n        limit: Maximum number of characters to return. Stops at newline,\n            EOF, or once the limit is reached (matching TextIOBase semantics).\n\n    Returns:\n        str: The next line from the file, including the newline if present.\n             Returns empty string at EOF.\n\n    Examples:\n        async with AsyncGzipTextFile(\"file.gz\", \"rt\") as f:\n            line = await f.readline()  # Read one line\n            while line:\n                print(line.rstrip())\n                line = await f.readline()\n    \"\"\"\n    if self._is_closed:\n        raise ValueError(\"I/O operation on closed file.\")\n    if self._mode_op != \"r\":\n        raise OSError(\"File not open for reading\")\n\n    if limit is None:\n        limit = -1\n    if limit == 0:\n        return \"\"\n\n    # Try to get a line from our buffer using newline-aware search\n    while True:\n        pos, length = self._get_line_terminator_pos(self._text_buffer)\n\n        if pos != -1:\n            # Found a line terminator - extract the line\n            end = pos + length\n            line = self._text_buffer[:end]\n            self._text_buffer = self._text_buffer[end:]\n            # Apply limit if specified\n            if limit != -1 and len(line) &gt; limit:\n                self._text_buffer = line[limit:] + self._text_buffer\n                line = line[:limit]\n            return line\n\n        # No terminator found - check if we have enough data for limit\n        if limit != -1 and len(self._text_buffer) &gt;= limit:\n            line = self._text_buffer[:limit]\n            self._text_buffer = self._text_buffer[limit:]\n            return line\n\n        # Need more data - try to read\n        has_more = await self._read_chunk_and_decode()\n        if not has_more:\n            # EOF reached - return whatever is in the buffer\n            if not self._text_buffer:\n                return \"\"\n            line = self._text_buffer\n            self._text_buffer = \"\"\n            # Apply limit if specified\n            if limit != -1 and len(line) &gt; limit:\n                self._text_buffer = line[limit:] + self._text_buffer\n                line = line[:limit]\n            return line\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipTextFile.readlines","title":"readlines  <code>async</code>","text":"<pre><code>readlines(hint: int = -1) -&gt; List[str]\n</code></pre> <p>Read and return a list of lines from the file.</p> <p>Parameters:</p> Name Type Description Default <code>hint</code> <code>int</code> <p>Optional size hint. If given and greater than 0, lines totaling approximately hint bytes are read (counted before decoding). The actual number of bytes read may be more or less than hint. If hint is -1 or not given, all remaining lines are read.</p> <code>-1</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: A list of lines from the file, each including any trailing</p> <code>List[str]</code> <p>newline character.</p> <p>Examples:</p> <p>async with AsyncGzipTextFile(\"file.gz\", \"rt\") as f:     lines = await f.readlines()  # Read all lines     for line in lines:         print(line.rstrip())</p>"},{"location":"api/#aiogzip.AsyncGzipTextFile.readlines--with-size-hint","title":"With size hint","text":"<p>async with AsyncGzipTextFile(\"file.gz\", \"rt\") as f:     lines = await f.readlines(1024)  # Read ~1KB of lines</p> Source code in <code>src/aiogzip/_text.py</code> <pre><code>async def readlines(self, hint: int = -1) -&gt; List[str]:\n    \"\"\"\n    Read and return a list of lines from the file.\n\n    Args:\n        hint: Optional size hint. If given and greater than 0, lines totaling\n            approximately hint bytes are read (counted before decoding).\n            The actual number of bytes read may be more or less than hint.\n            If hint is -1 or not given, all remaining lines are read.\n\n    Returns:\n        List[str]: A list of lines from the file, each including any trailing\n        newline character.\n\n    Examples:\n        async with AsyncGzipTextFile(\"file.gz\", \"rt\") as f:\n            lines = await f.readlines()  # Read all lines\n            for line in lines:\n                print(line.rstrip())\n\n        # With size hint\n        async with AsyncGzipTextFile(\"file.gz\", \"rt\") as f:\n            lines = await f.readlines(1024)  # Read ~1KB of lines\n    \"\"\"\n    if self._is_closed:\n        raise ValueError(\"I/O operation on closed file.\")\n    if self._mode_op != \"r\":\n        raise OSError(\"File not open for reading\")\n\n    lines: List[str] = []\n    total_size = 0\n\n    while True:\n        line = await self.readline()\n        if not line:\n            break\n        lines.append(line)\n        total_size += len(line)\n        if hint &gt; 0 and total_size &gt;= hint:\n            break\n\n    return lines\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipTextFile.write","title":"write  <code>async</code>","text":"<pre><code>write(data: str) -&gt; int\n</code></pre> <p>Encodes and writes text data to the file.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>str</code> <p>String to write</p> required <p>Examples:</p> <p>async with AsyncGzipTextFile(\"file.gz\", \"wt\") as f:     await f.write(\"Hello, World!\")  # String input</p> Source code in <code>src/aiogzip/_text.py</code> <pre><code>async def write(self, data: str) -&gt; int:\n    \"\"\"\n    Encodes and writes text data to the file.\n\n    Args:\n        data: String to write\n\n    Examples:\n        async with AsyncGzipTextFile(\"file.gz\", \"wt\") as f:\n            await f.write(\"Hello, World!\")  # String input\n    \"\"\"\n    if not self._writing_mode:\n        raise OSError(\"File not open for writing\")\n    if self._is_closed:\n        raise ValueError(\"I/O operation on closed file.\")\n    if self._binary_file is None:\n        raise ValueError(\"File not opened. Use async context manager.\")\n\n    if not isinstance(data, str):\n        raise TypeError(\"write() argument must be str, not bytes\")\n\n    # Translate newlines according to Python's text I/O semantics\n    text_to_encode = data\n    if self._newline is None:\n        # Translate \\n to os.linesep on write\n        text_to_encode = text_to_encode.replace(\"\\n\", os.linesep)\n    elif self._newline in (\"\\n\", \"\\r\", \"\\r\\n\"):\n        text_to_encode = text_to_encode.replace(\"\\n\", self._newline)\n    else:\n        # newline == '' means no translation; any other value treat as no translation\n        pass\n\n    # Encode string to bytes\n    encoded_data = text_to_encode.encode(self._encoding, errors=self._errors)\n    await self._binary_file.write(encoded_data)\n    return len(data)\n</code></pre>"},{"location":"api/#aiogzip.AsyncGzipTextFile.writelines","title":"writelines  <code>async</code>","text":"<pre><code>writelines(lines: Iterable[str]) -&gt; None\n</code></pre> <p>Write a list of lines to the file.</p> <p>Note that newlines are not added automatically; each string in the iterable should include its own line terminator if desired.</p> <p>Parameters:</p> Name Type Description Default <code>lines</code> <code>Iterable[str]</code> <p>An iterable of strings to write.</p> required <p>Examples:</p> <p>async with AsyncGzipTextFile(\"file.gz\", \"wt\") as f:     await f.writelines([\"line1\\n\", \"line2\\n\", \"line3\\n\"])</p>"},{"location":"api/#aiogzip.AsyncGzipTextFile.writelines--from-a-generator","title":"From a generator","text":"<p>async with AsyncGzipTextFile(\"file.gz\", \"wt\") as f:     await f.writelines(f\"{i}\\n\" for i in range(100))</p> Source code in <code>src/aiogzip/_text.py</code> <pre><code>async def writelines(self, lines: Iterable[str]) -&gt; None:\n    \"\"\"\n    Write a list of lines to the file.\n\n    Note that newlines are not added automatically; each string in the\n    iterable should include its own line terminator if desired.\n\n    Args:\n        lines: An iterable of strings to write.\n\n    Examples:\n        async with AsyncGzipTextFile(\"file.gz\", \"wt\") as f:\n            await f.writelines([\"line1\\\\n\", \"line2\\\\n\", \"line3\\\\n\"])\n\n        # From a generator\n        async with AsyncGzipTextFile(\"file.gz\", \"wt\") as f:\n            await f.writelines(f\"{i}\\\\n\" for i in range(100))\n    \"\"\"\n    if not self._writing_mode:\n        raise OSError(\"File not open for writing\")\n    if self._is_closed:\n        raise ValueError(\"I/O operation on closed file.\")\n\n    for line in lines:\n        await self.write(line)\n</code></pre>"},{"location":"api/#aiogzip.WithAsyncRead","title":"WithAsyncRead","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for async file-like objects that can be read.</p>"},{"location":"api/#aiogzip.WithAsyncReadWrite","title":"WithAsyncReadWrite","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for async file-like objects that can be read and written.</p>"},{"location":"api/#aiogzip.WithAsyncWrite","title":"WithAsyncWrite","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for async file-like objects that can be written.</p>"},{"location":"api/#aiogzip.AsyncGzipFile","title":"AsyncGzipFile","text":"<pre><code>AsyncGzipFile(filename: Union[str, bytes, Path, None], mode: str = 'rb', **kwargs: Any) -&gt; Union[AsyncGzipBinaryFile, AsyncGzipTextFile]\n</code></pre> <p>Factory function that returns the appropriate AsyncGzip class based on mode.</p> <p>This provides backward compatibility with the original AsyncGzipFile interface while using the new separated binary and text file classes.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Union[str, bytes, Path, None]</code> <p>Path to the file</p> required <code>mode</code> <code>str</code> <p>File mode ('rb', 'wb', 'rt', 'wt', etc.)</p> <code>'rb'</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments passed to the appropriate class</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[AsyncGzipBinaryFile, AsyncGzipTextFile]</code> <p>AsyncGzipBinaryFile for binary modes ('rb', 'wb', 'ab')</p> <code>Union[AsyncGzipBinaryFile, AsyncGzipTextFile]</code> <p>AsyncGzipTextFile for text modes ('rt', 'wt', 'at')</p> Source code in <code>src/aiogzip/__init__.py</code> <pre><code>def AsyncGzipFile(\n    filename: Union[str, bytes, Path, None], mode: str = \"rb\", **kwargs: Any\n) -&gt; Union[AsyncGzipBinaryFile, AsyncGzipTextFile]:\n    \"\"\"\n    Factory function that returns the appropriate AsyncGzip class based on mode.\n\n    This provides backward compatibility with the original AsyncGzipFile interface\n    while using the new separated binary and text file classes.\n\n    Args:\n        filename: Path to the file\n        mode: File mode ('rb', 'wb', 'rt', 'wt', etc.)\n        **kwargs: Additional arguments passed to the appropriate class\n\n    Returns:\n        AsyncGzipBinaryFile for binary modes ('rb', 'wb', 'ab')\n        AsyncGzipTextFile for text modes ('rt', 'wt', 'at')\n    \"\"\"\n    if not isinstance(mode, str):\n        raise TypeError(\"mode must be a string\")\n    text_mode = \"t\" in mode\n    if not text_mode:\n        for arg_name in (\"encoding\", \"errors\", \"newline\"):\n            if kwargs.get(arg_name) is not None:\n                raise ValueError(f\"Argument '{arg_name}' not supported in binary mode\")\n        kwargs = {\n            key: value\n            for key, value in kwargs.items()\n            if key not in {\"encoding\", \"errors\", \"newline\"}\n        }\n    if text_mode:\n        return AsyncGzipTextFile(filename, mode, **kwargs)\n    else:\n        return AsyncGzipBinaryFile(filename, mode, **kwargs)\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome! This project uses <code>setuptools</code> for packaging and modern tooling for quality assurance.</p>"},{"location":"contributing/#development-setup","title":"Development Setup","text":"<ol> <li> <p>Clone the repository:</p> <pre><code>git clone https://github.com/geoff-davis/aiogzip.git\ncd aiogzip\n</code></pre> </li> <li> <p>Install dependencies:</p> <p>We recommend using a virtual environment.</p> <pre><code>python -m venv .venv\nsource .venv/bin/activate\npip install -e \".[dev,csv,docs]\"\n</code></pre> </li> <li> <p>Install Pre-commit Hooks:</p> <p>This project uses <code>pre-commit</code> to ensure code quality.</p> <pre><code>pre-commit install\n</code></pre> </li> </ol>"},{"location":"contributing/#running-tests","title":"Running Tests","text":"<p>Run the full test suite using <code>pytest</code>:</p> <pre><code>pytest\n</code></pre>"},{"location":"contributing/#code-quality","title":"Code Quality","text":"<p>We use <code>ruff</code> for linting and formatting, and both <code>mypy</code> and <code>ty</code> for static type checking. These are run automatically by pre-commit, but you can run them manually:</p> <pre><code>ruff check .\nruff format .\nmypy src\nty check src\n</code></pre>"},{"location":"contributing/#package-layout","title":"Package Layout","text":"<p>Core implementation is split across focused modules in <code>src/aiogzip</code>:</p> <ul> <li><code>_common.py</code>: shared constants, validation helpers, and protocols</li> <li><code>_binary.py</code>: <code>AsyncGzipBinaryFile</code> implementation</li> <li><code>_text.py</code>: <code>AsyncGzipTextFile</code> implementation</li> <li><code>__init__.py</code>: public API exports and <code>AsyncGzipFile</code> factory</li> </ul> <p>When adding new internals, prefer one of the focused modules and keep <code>__init__.py</code> as the stable public API surface.</p>"},{"location":"contributing/#documentation","title":"Documentation","text":"<p>To build the documentation locally:</p> <pre><code>mkdocs serve\n</code></pre> <p>Then open http://localhost:8000 in your browser.</p>"},{"location":"examples/","title":"Examples","text":"<p>This guide provides practical examples for using <code>aiogzip</code> in various scenarios.</p>"},{"location":"examples/#csv-processing-with-aiocsv","title":"CSV Processing with <code>aiocsv</code>","text":"<p><code>aiogzip</code> pairs perfectly with <code>aiocsv</code> for efficient, asynchronous CSV processing.</p>"},{"location":"examples/#reading-a-csv-file","title":"Reading a CSV File","text":"<pre><code>import asyncio\nimport aiocsv\nfrom aiogzip import AsyncGzipTextFile\n\nasync def read_csv():\n    async with AsyncGzipTextFile(\"data.csv.gz\", \"rt\", encoding=\"utf-8\", newline=\"\") as f:\n        # Use AsyncDictReader for dictionary-based access\n        async for row in aiocsv.AsyncDictReader(f):\n            print(f\"Name: {row['name']}, Age: {row['age']}\")\n\nasyncio.run(read_csv())\n</code></pre>"},{"location":"examples/#writing-a-csv-file","title":"Writing a CSV File","text":"<pre><code>import asyncio\nimport aiocsv\nfrom aiogzip import AsyncGzipTextFile\n\nasync def write_csv():\n    data = [\n        {\"name\": \"Alice\", \"age\": 30, \"city\": \"New York\"},\n        {\"name\": \"Bob\", \"age\": 25, \"city\": \"Los Angeles\"},\n    ]\n\n    async with AsyncGzipTextFile(\"output.csv.gz\", \"wt\", encoding=\"utf-8\", newline=\"\") as f:\n        writer = aiocsv.AsyncDictWriter(f, fieldnames=[\"name\", \"age\", \"city\"])\n        await writer.writeheader()\n        for row in data:\n            await writer.writerow(row)\n\nasyncio.run(write_csv())\n</code></pre>"},{"location":"examples/#json-lines-jsonl-processing","title":"JSON Lines (JSONL) Processing","text":"<p>Processing large compressed JSONL files is a common task in data engineering.</p>"},{"location":"examples/#reading-jsonl","title":"Reading JSONL","text":"<pre><code>import asyncio\nimport json\nfrom aiogzip import AsyncGzipTextFile\n\nasync def process_jsonl():\n    async with AsyncGzipTextFile(\"logs.jsonl.gz\", \"rt\") as f:\n        async for line in f:\n            try:\n                record = json.loads(line)\n                if record.get(\"level\") == \"ERROR\":\n                    print(f\"Error found: {record['message']}\")\n            except json.JSONDecodeError:\n                print(f\"Skipping invalid JSON: {line[:50]}...\")\n\nasyncio.run(process_jsonl())\n</code></pre>"},{"location":"examples/#concurrent-file-processing","title":"Concurrent File Processing","text":"<p>One of the biggest advantages of <code>aiogzip</code> is the ability to process multiple files concurrently without blocking the event loop.</p> <pre><code>import asyncio\nfrom aiogzip import AsyncGzipTextFile\n\nasync def process_file(filename):\n    print(f\"Starting {filename}...\")\n    line_count = 0\n    async with AsyncGzipTextFile(filename, \"rt\") as f:\n        async for _ in f:\n            line_count += 1\n    print(f\"Finished {filename}: {line_count} lines\")\n    return line_count\n\nasync def main():\n    files = [\"data1.gz\", \"data2.gz\", \"data3.gz\"]\n\n    # Create tasks for all files\n    tasks = [process_file(f) for f in files]\n\n    # Run them concurrently\n    results = await asyncio.gather(*tasks)\n\n    print(f\"Total lines processed: {sum(results)}\")\n\n# To run this example, ensure the files exist\n# asyncio.run(main())\n</code></pre>"},{"location":"examples/#error-handling","title":"Error Handling","text":"<p><code>aiogzip</code> raises standard <code>OSError</code> (or subclasses) for I/O issues, ensuring consistency with Python's built-in file handling.</p> <pre><code>import asyncio\nfrom aiogzip import AsyncGzipFile\n\nasync def safe_read():\n    try:\n        async with AsyncGzipFile(\"non_existent.gz\", \"rb\") as f:\n            await f.read()\n    except FileNotFoundError:\n        print(\"File not found!\")\n    except OSError as e:\n        print(f\"An I/O error occurred: {e}\")\n\nasyncio.run(safe_read())\n</code></pre>"},{"location":"performance/","title":"Performance Guide","text":"<p><code>aiogzip</code> is designed to be a high-performance, asynchronous alternative to Python's <code>gzip</code> module. This guide details its performance characteristics and provides tips for optimization.</p>"},{"location":"performance/#benchmark-summary","title":"Benchmark Summary","text":"<p>All benchmarks were conducted on standard hardware using Python 3.12+.</p>"},{"location":"performance/#text-operations-winner-aiogzip","title":"Text Operations (Winner: <code>aiogzip</code>)","text":"<p><code>aiogzip</code> is significantly optimized for text processing, often outperforming the standard <code>gzip</code> module due to efficient buffering and async handling.</p> Operation aiogzip gzip (sync) Speedup Bulk Text Read/Write ~35 MB/s ~14 MB/s 2.5x Faster JSONL Processing - - 1.8x Faster Line Iteration 1.2M lines/sec - - <p>Why? <code>aiogzip</code> uses optimized UTF-8 decoding strategies (using <code>codecs.getincrementaldecoder</code>) and manages buffers efficiently to minimize encoding/decoding overhead.</p>"},{"location":"performance/#binary-operations-tie","title":"Binary Operations (Tie)","text":"<p>For bulk binary I/O, <code>aiogzip</code> matches the throughput of standard <code>gzip</code>.</p> Operation aiogzip gzip (sync) Speedup Bulk Binary I/O ~52 MB/s ~53 MB/s Equivalent Small Chunks 1.7M ops/sec 1.3M ops/sec 1.3x Faster"},{"location":"performance/#concurrency-winner-aiogzip","title":"Concurrency (Winner: <code>aiogzip</code>)","text":"<p>When processing multiple files, especially where I/O latency (disk/network) is involved, <code>aiogzip</code> shines by not blocking the event loop.</p> <ul> <li>Concurrent Processing: 1.5x Faster (simulated I/O latency).</li> <li>Allows the main thread to remain responsive (e.g., for a web server) while processing heavy compression tasks.</li> </ul>"},{"location":"performance/#optimization-tips","title":"Optimization Tips","text":""},{"location":"performance/#1-choose-the-right-chunk-size","title":"1. Choose the Right Chunk Size","text":"<p>The default <code>chunk_size</code> is 64KB, and there is intentionally no upper bound.</p> <ul> <li>Increase it (e.g., <code>128*1024</code> or <code>1024*1024</code>) for large file throughput if you have memory to spare.</li> <li>Decrease it if you are memory constrained and processing massive files.</li> <li>If you push chunk sizes into the multi-megabyte range, budget the extra memory per open file to avoid accidental OOMs.</li> </ul> <pre><code># Example: Using a larger chunk size for speed\nasync with AsyncGzipBinaryFile(\"large.gz\", \"rb\", chunk_size=1024*1024) as f:\n    ...\n</code></pre>"},{"location":"performance/#2-use-read-1-carefully","title":"2. Use <code>read(-1)</code> Carefully","text":"<p>Reading the entire file into memory (<code>read(-1)</code>) is the fastest way to process data if it fits in RAM. <code>aiogzip</code> optimizes this by reading chunks and joining them at the end.</p> <p>However, for multi-gigabyte files, always prefer streaming (line-by-line or fixed-size reads) to avoid OOM (Out of Memory) crashes.</p>"},{"location":"performance/#3-text-vs-binary","title":"3. Text vs. Binary","text":"<ul> <li>If you need text, use <code>AsyncGzipTextFile</code> (or <code>mode=\"rt\"/\"wt\"</code>). It handles decoding more efficiently than you can typically do manually in Python loop.</li> <li>If you just need to move bytes (e.g., upload to S3), use <code>AsyncGzipBinaryFile</code>.</li> </ul>"},{"location":"performance/#4-buffer-management","title":"4. Buffer Management","text":"<p><code>aiogzip</code> maintains an internal buffer.</p> <ul> <li>Binary Mode: Uses an efficient offset-pointer strategy to avoid expensive memory copies (<code>del buffer[:n]</code>) when reading small chunks.</li> <li>Text Mode: Buffers decoded text to handle split multi-byte characters and split newlines correctly.</li> </ul>"}]}